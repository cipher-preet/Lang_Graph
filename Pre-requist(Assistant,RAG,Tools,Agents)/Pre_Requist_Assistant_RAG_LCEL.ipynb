{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7e113d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee6b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "TAVILY_API_KEY=os.getenv(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_PROJECT=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498da0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "os.environ[\"GROQ_API_KEY\"]= GROQ_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=LANGCHAIN_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1df3ff14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1300af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f031063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")'''\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "llm=ChatGroq(model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebaf7f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodbye take care yourself\n"
     ]
    }
   ],
   "source": [
    "# simple AI Assistance\n",
    "\n",
    "while True:\n",
    "    question=input(\"type your question. if you want to quit the chat write quit\")\n",
    "    if question !=\"quit\":\n",
    "        print(llm.invoke(question).content)\n",
    "    else:\n",
    "        print(\"goodbye take care yourself\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bef792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39be5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e08c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56736b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"firstchat\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f8cc24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_memory=RunnableWithMessageHistory(llm,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74202deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Preet.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_memory.invoke((\"Hi! I'm preet\"),config=config).content\n",
    "model_with_memory.invoke((\"tell me what is my name?\"),config=config).content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a082e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "# from langchain import PromptTemplate\n",
    "# from langchain_core.runnables import RunnableParallel, RunnablePassthrough , RunnableLambda\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ### Reading the txt files from source directory\n",
    "\n",
    "# loader = DirectoryLoader('../data', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "# docs = loader.load()\n",
    "\n",
    "# ### Creating Chunks using RecursiveCharacterTextSplitter\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=50,\n",
    "#     chunk_overlap=10,\n",
    "#     length_function=len\n",
    "# )\n",
    "# new_docs = text_splitter.split_documents(documents=docs)\n",
    "# doc_strings = [doc.page_content for doc in new_docs]\n",
    "\n",
    "# ###  BGE Embddings\n",
    "\n",
    "# '''from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "# model_kwargs = {'device': 'cpu'}\n",
    "# encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "# embeddings = HuggingFaceBgeEmbeddings(\n",
    "#     model_name=model_name,\n",
    "#     model_kwargs=model_kwargs,\n",
    "#     encode_kwargs=encode_kwargs,\n",
    "# )\n",
    "# '''\n",
    "\n",
    "# ### Creating Retriever using Vector DB\n",
    "\n",
    "# db = Chroma.from_documents(new_docs, embeddings)\n",
    "# retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# template = \"\"\"Answer the question based only on the following context:\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "# \"\"\"\n",
    "# prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# retrieval_chain = (\n",
    "#     RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "#     | prompt\n",
    "#     | llm\n",
    "#     | StrOutputParser()\n",
    "#     )\n",
    "\n",
    "\n",
    "# question =\"what is llama3? can you highlight 3 important points?\"\n",
    "# print(retrieval_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7e1bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's Start with Tools and Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f19f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aae074d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=5, doc_content_chars_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "197356f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dc84098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b156cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57ad2bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'query to look up on wikipedia',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b4365e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.return_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90641984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of \n"
     ]
    }
   ],
   "source": [
    "print(tool.run({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4c200fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7104dce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LangGraph_End_To_End\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b4a5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiInputs(BaseModel):\n",
    "    query: str = Field(description=\"query to look up in Wikipedia, should be 3 or less words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23a6e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool=WikipediaQueryRun(\n",
    "#     name=\"wiki-tool\",\n",
    "#     description=\"look up things in wikipedia\",\n",
    "#     args_schema=WikiInputs,\n",
    "#     api_wrapper=api_wrapper,\n",
    "#     return_direct=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01c09cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### youtube search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a42b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "861e2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool=YouTubeSearchTool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cc0fd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cd39bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "029f4555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PREET\\AppData\\Local\\Temp\\ipykernel_18632\\834566.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tool = TavilySearchResults()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cricket Schedule - International, domestic and T20 matches - Cricbuzz',\n",
       "  'url': 'https://www.cricbuzz.com/cricket-schedule/upcoming-series/league',\n",
       "  'content': 'Schedule of International, T20 League, Indian, Australian and English domestic cricket matches on Cricbuzz.',\n",
       "  'score': 0.67140645},\n",
       " {'title': 'Cricket Fixtures: List of Ongoing, Upcoming and Concluded Series',\n",
       "  'url': 'https://www.espncricinfo.com/cricket-fixtures',\n",
       "  'content': 'Find the list of domestic and international current cricket series, upcoming series, and recently concluded tournaments on our comprehensive cricket',\n",
       "  'score': 0.6326168},\n",
       " {'title': 'Cricket Schedule - Check International and Domestic matches on ...',\n",
       "  'url': 'https://www.fancode.com/cricket/schedule',\n",
       "  'content': 'Get the latest schedule, fixtures and results of Cricket international and domestic matches on FanCode. Find current and upcoming Cricket match information',\n",
       "  'score': 0.56575525},\n",
       " {'title': 'Cricket Schedule - Upcoming International, domestic and T20 Series',\n",
       "  'url': 'https://www.cricbuzz.com/cricket-schedule/series',\n",
       "  'content': 'View Cricket Schedule of upcoming International, domestic and T20 Series on Cricbuzz. ... ICC World Test Championship · ICC World Cup Super League · Records.',\n",
       "  'score': 0.48440504},\n",
       " {'title': 'Cricket Schedule, Upcoming ODI, Test, T20 ... - Hindustan Times',\n",
       "  'url': 'https://www.hindustantimes.com/cricket/schedule',\n",
       "  'content': 'Cricket Schedule: Get all the latest Cricket schedules of Upcoming International and Domestic ODI, Test and T20 Series on Crickit by HT.',\n",
       "  'score': 0.48221022}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool = TavilySearchResults()\n",
    "tool.invoke({\"query\": \" Fetches all currently ongoing or live cricket matches including international, domestic, and league tournaments. Filters out previews, opinions, and non-authoritative content.\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cad0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "847a6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor,create_openai_functions_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0881787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"You are an assistant.\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "705da2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tavily_tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00951e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22a33a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_functions_agent(llm, tools, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d15c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c1804aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'who was the mahatma gandhi', 'output': ''}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"who was the mahatma gandhi\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce000c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d0bb79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
